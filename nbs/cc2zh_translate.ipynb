{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EtssVJyGkmU"
   },
   "source": [
    "# Translate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using [this nice dataset](https://github.com/BangBOOM/Classical-Chinese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.imports import *\n",
    "from forgebox.thunder.callbacks import DataFrameMetricsCallback\n",
    "from gc_utils.env import *\n",
    "from datasets import load_dataset\n",
    "# from fastai.text.all import *\n",
    "from unpackai.nlp import *\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_all_punkt(text):\n",
    "    \"\"\"\n",
    "    Removes all punctuation from Chinese text.\n",
    "\n",
    "    :param text: text to remove punctuation from\n",
    "    :return: text with no punctuation\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'亳州水军千户胡进等领骑兵渡淝水逾荆山与宋兵战杀获甚众赏钞币有差'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_all_punkt(\"亳州水军千户胡进等领骑兵渡淝水，逾荆山，与宋兵战，杀获甚众，赏钞币有差。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path(sys_loc('DATA')/\"nlp\"/\"zh\"/\"cc_vs_zh\")\n",
    "TO_CLASSICAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbXuwqr0KEr8"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file = list(DATA.rglob(\"data/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file_to_lines(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return lines\n",
    "\n",
    "def pairing_the_file(files,kw):\n",
    "    pairs = []\n",
    "    for file in files:\n",
    "        if kw not in file.name:\n",
    "            file1 = file\n",
    "            file2 = f\"{file}{kw}\"\n",
    "            pairs.append((file1,file2))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairing_the_file(all_file,\"翻译\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pairs(pairs):\n",
    "    chunks = []\n",
    "    for pair in tqdm(pairs, leave=False):\n",
    "        file1,file2 = pair\n",
    "        lines1 = open_file_to_lines(file1)\n",
    "        lines2 = open_file_to_lines(file2)\n",
    "        chunks.append(pd.DataFrame({\"classical\":lines1,\"modern\":lines2}))\n",
    "    return pd.concat(chunks).sample(frac=1.).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = open_pairs(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_df.rename(\n",
    "    columns = dict(\n",
    "        zip([\"modern\",\"classical\"],\n",
    "             [\"source\",\"target\"] if TO_CLASSICAL else [\"target\",\"source\",]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>谏议大夫宁原悌上言：以为先朝悖逆庶人以爱女骄盈而及祸，新城、宜都以庶孽抑损而获全。</td>\n",
       "      <td>谏议大夫宁原悌向唐睿宗进言认为：先朝悖逆庶人作为中宗和韦后的爱女而骄傲自满，终于难逃杀身之祸...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>意等漏卮，江河无以充其溢。</td>\n",
       "      <td>思想像渗漏的酒器，长江、黄河无法来填满他的欲壑。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>琥珀太多，及差，痕不灭，左颊有赤点如痣。</td>\n",
       "      <td>因琥珀用得过多，到伤愈时，邓夫人左颊疤疮没有完全去掉，脸上留下一颗象痣一样的红点。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>督军疾进，师至阴山，遇其斥候千余帐，皆俘以随军。</td>\n",
       "      <td>于是督军疾进，军队行进到阴山，遇到颉利可汗的哨兵千余帐，把他们全部俘获，并押着他们随军行动。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>莽曰夕阴。</td>\n",
       "      <td>王莽时叫夕阴县。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      source  \\\n",
       "0  谏议大夫宁原悌上言：以为先朝悖逆庶人以爱女骄盈而及祸，新城、宜都以庶孽抑损而获全。   \n",
       "1                              意等漏卮，江河无以充其溢。   \n",
       "2                       琥珀太多，及差，痕不灭，左颊有赤点如痣。   \n",
       "3                   督军疾进，师至阴山，遇其斥候千余帐，皆俘以随军。   \n",
       "4                                      莽曰夕阴。   \n",
       "\n",
       "                                              target  \n",
       "0  谏议大夫宁原悌向唐睿宗进言认为：先朝悖逆庶人作为中宗和韦后的爱女而骄傲自满，终于难逃杀身之祸...  \n",
       "1                           思想像渗漏的酒器，长江、黄河无法来填满他的欲壑。  \n",
       "2          因琥珀用得过多，到伤愈时，邓夫人左颊疤疮没有完全去掉，脸上留下一颗象痣一样的红点。  \n",
       "3     于是督军疾进，军队行进到阴山，遇到颉利可汗的哨兵千余帐，把他们全部俘获，并押着他们随军行动。  \n",
       "4                                           王莽时叫夕阴县。  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ukyVGg8HmSd-"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModel,\n",
    "    EncoderDecoderModel\n",
    "    )\n",
    "\n",
    "# we find a English parsing encoder, as a pretrained bert is good at understanding english\n",
    "# BERT is short for Bidirectional **Encoder** Representations from Transformers, which consists fully of encoder blocks\n",
    "ENCODER_PRETRAINED = \"bert-base-chinese\"\n",
    "# we find a Chinese writing model for decoder, as decoder is the part of the model that can write stuff\n",
    "DECODER_PRETRAINED = \"uer/gpt2-chinese-poem\"\n",
    "\n",
    "encoder_tokenizer = AutoTokenizer.from_pretrained(ENCODER_PRETRAINED)\n",
    "\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    ENCODER_PRETRAINED # notice we use the BERT's tokenizer here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytoch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(Dataset):\n",
    "    def __init__(\n",
    "        self, df, tokenizer, target_tokenizer,\n",
    "        max_len=128,\n",
    "        no_punkt:bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        no_punkt, do we ramdomly remove punctuation\n",
    "        from source sentence\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.target_tokenizer = target_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.no_punkt = no_punkt\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return dict(self.df.iloc[idx])\n",
    "\n",
    "    def collate(self, batch):\n",
    "        batch_df = pd.DataFrame(list(batch))\n",
    "        x, y = batch_df.source, batch_df.target\n",
    "        # there is a random no punctuation mode\n",
    "        # for source text\n",
    "        # as some of the classical text we get\n",
    "        # might be whole chunk of paragraph without\n",
    "        # any punctuation\n",
    "        if self.no_punkt:\n",
    "            x = list(i if random.random()>.5\n",
    "                     else remove_all_punkt(i)\n",
    "                     for i in x)\n",
    "        else:\n",
    "            x = list(x)\n",
    "        x_batch = self.tokenizer(\n",
    "            x,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        y_batch = self.target_tokenizer(\n",
    "            list(y),\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        x_batch['decoder_input_ids'] = y_batch['input_ids']\n",
    "        x_batch['labels'] = y_batch['input_ids'].clone()\n",
    "        x_batch['labels'][x_batch['labels'] == self.tokenizer.pad_token_id] = -100\n",
    "        return x_batch\n",
    "\n",
    "    def dataloader(self, batch_size, shuffle=True):\n",
    "        return DataLoader(\n",
    "            self,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            collate_fn=self.collate,\n",
    "        )\n",
    "\n",
    "    def split_train_valid(self, valid_size=0.1):\n",
    "        split_index = int(len(self) * (1 - valid_size))\n",
    "        cls = type(self)\n",
    "        shuffled = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        train_set = cls(\n",
    "            shuffled.iloc[:split_index],\n",
    "            tokenizer=self.tokenizer,\n",
    "            target_tokenizer=self.target_tokenizer,\n",
    "            max_len=self.max_len,\n",
    "            no_punkt=self.no_punkt,\n",
    "        )\n",
    "        valid_set = cls(\n",
    "            shuffled.iloc[split_index:],\n",
    "            tokenizer=self.tokenizer,\n",
    "            target_tokenizer=self.target_tokenizer,\n",
    "            max_len=self.max_len,\n",
    "            no_punkt=self.no_punkt,\n",
    "        )\n",
    "        return train_set, valid_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqData(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, df,\n",
    "        tokenizer,\n",
    "        target_tokenizer,\n",
    "        batch_size=12,\n",
    "        max_len=128,\n",
    "        no_punkt:bool=False):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.ds = Seq2Seq(df,\n",
    "                          tokenizer,\n",
    "                          target_tokenizer,\n",
    "                          max_len=max_len,\n",
    "                          no_punkt=no_punkt)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.target_tokenizer = target_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_set, self.valid_set = self.ds.split_train_valid()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_set.dataloader(\n",
    "            batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.valid_set.dataloader(\n",
    "            batch_size=self.batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = Seq2SeqData(\n",
    "    df, encoder_tokenizer,\n",
    "    decoder_tokenizer,\n",
    "    batch_size=28,\n",
    "    max_len=256,\n",
    "    no_punkt=False if TO_CLASSICAL else True,)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1921, 5688,  ...,    0,    0,    0],\n",
       "        [ 101, 2828, 1062,  ...,    0,    0,    0],\n",
       "        [ 101, 1039, 1469,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101,  718,  886,  ...,    0,    0,    0],\n",
       "        [ 101, 1071, 1095,  ...,    0,    0,    0],\n",
       "        [ 101, 1062, 1920,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_input_ids': tensor([[ 101, 1921, 5688,  ...,    0,    0,    0],\n",
       "        [ 101, 1315,  752,  ...,    0,    0,    0],\n",
       "        [ 101, 1039, 1469,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 3727, 4374,  ...,    0,    0,    0],\n",
       "        [ 101, 7342, 5093,  ...,    0,    0,    0],\n",
       "        [ 101, 1155, 4893,  ...,    0,    0,    0]]), 'labels': tensor([[ 101, 1921, 5688,  ..., -100, -100, -100],\n",
       "        [ 101, 1315,  752,  ..., -100, -100, -100],\n",
       "        [ 101, 1039, 1469,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [ 101, 3727, 4374,  ..., -100, -100, -100],\n",
       "        [ 101, 7342, 5093,  ..., -100, -100, -100],\n",
       "        [ 101, 1155, 4893,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = next(iter(data_module.train_dataloader()))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we are doing clasical Chinese to modern Chinese, we can randomly set half of the input without any punctuation, as many data source might be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['天 节 八 星 ， 在 毕 、 附 耳 南 ， 主 使 臣 持 节 宣 威 四 方 。',\n",
       " '把 公 子 成 的 话 报 告 给 赵 武 灵 王 。 武 灵 王 说 ： 我 就 知 道 王 叔 反 对 这 件 事 。 于 是 马 上 就 去 公 子 成 家 里 ， 亲 自 向 他 阐 述 自 己 的 观 点 ： 大 凡 衣 服 是 为 了 便 于 穿 用 ， 礼 制 是 为 了 便 于 办 事 。',\n",
       " '元 和 五 年 已 前 租 赋 并 放 。',\n",
       " '凡 杀 三 人 ， 伤 五 人 ， 手 驱 郎 吏 二 十 余 人 。',\n",
       " '杨 石 二 少 年 为 民 害 简 置 狱 中 谕 以 祸 福 咸 感 悟 愿 自 赎',\n",
       " '辛 亥 诸 将 自 汉 口 开 坝 引 船 入 沦 河 先 遣 万 户 阿 剌 罕 以 兵 拒 沙 芜 口 逼 近 武 矶 巡 视 阳 罗 城 堡 径 趋 沙 芜 遂 入 大 江',\n",
       " '江 东 民 户 殷 盛 风 俗 峻 刻 强 弱 相 陵 奸 吏 蜂 起 符 书 一 下 文 摄 相 续',\n",
       " '昏 夜 ， 平 善 ， 乡 晨 ， 傅 绔 袜 欲 起 ， 因 失 衣 ， 不 能 言 ， 昼 漏 上 十 刻 而 崩 。',\n",
       " '子 十 三 篇',\n",
       " '扶 风 民 鲁 悉 达 ， 纠 合 乡 人 以 保 新 蔡 ， 力 田 蓄 谷 。',\n",
       " '明 年 ， 又 贬 武 安 军 节 度 副 使 、 永 州 安 置 。',\n",
       " '良 久 徐 曰 恬 罪 故 当 死 矣',\n",
       " '部 曲 将 田 泓 请 没 水 潜 行 趣 彭 城 ， 玄 遣 之 。',\n",
       " '必 久 停 留 ， 恐 非 天 意 也 。',\n",
       " '具 传 其 业 又 默 讲 论 义 理 五 经 诸 子 无 不 该 览 加 博 好 技 艺 算 术 卜 数 医 药 弓 弩 机 械 之 巧 皆 致 思 焉',\n",
       " '苏 秦 初 合 纵 至 燕',\n",
       " '讼 者 言 词 忿 争 理 无 所 屈',\n",
       " '高 祖 闻 之 ， 曰 ： 二 将 和 ， 师 必 济 矣 。',\n",
       " '谧 兄 谌 字 兴 伯 性 平 和',\n",
       " '平 受 诏 ， 立 复 驰 至 宫 ， 哭 殊 悲 ； 因 固 请 得 宿 卫 中 。',\n",
       " '属 淮 阴 ， 击 破 齐 历 下 军 ， 击 田 解 。',\n",
       " '惇 与 蔡 卞 将 必 置 之 死 ， 因 使 者 入 海 岛 诛 陈 衍 ， 讽 使 者 过 安 世 ， 胁 使 自 裁 。',\n",
       " '是 后 ， 将 士 功 赏 视 立 功 之 地 ， 准 例 奏 行 。',\n",
       " '左 右 欲 兵 之 。 太 公 曰 ： 此 义 人 也 。',\n",
       " '僧 知 是 非 常 人 顶 礼 忏 悔 授 书 与 之',\n",
       " '乃 使 良 还',\n",
       " '其 冢 人 祠 之 不 绝',\n",
       " '公 大 怒 ， 揖 出 之 。']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tokenizer.batch_decode(\n",
    "    inputs.input_ids,skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92iwRu6Oqbzb"
   },
   "source": [
    "### Load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZkPxJVTm8Ng",
    "outputId": "dcecf16e-22fe-4c25-9ffb-aae9d75785f3"
   },
   "outputs": [],
   "source": [
    "# encoder = AutoModel.from_pretrained(ENCODER_PRETRAINED, proxies={\"http\":\"bifrost:3128\"})\n",
    "# decoder = AutoModelForCausalLM.from_pretrained(DECODER_PRETRAINED, add_cross_attention=True,\n",
    "#                                                proxies={\"http\":\"bifrost:3128\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pajv5ridLamp"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1zqJXDsCUw-"
   },
   "source": [
    "We create a seq2seq model by using pretrained encoder + pretrained decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at uer/gpt2-chinese-poem and are newly initialized: ['transformer.h.6.crossattention.bias', 'transformer.h.4.crossattention.bias', 'transformer.h.6.crossattention.masked_bias', 'transformer.h.6.crossattention.c_attn.weight', 'transformer.h.2.crossattention.bias', 'transformer.h.3.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_attn.weight', 'transformer.h.10.crossattention.c_proj.weight', 'transformer.h.10.crossattention.q_attn.weight', 'transformer.h.3.ln_cross_attn.weight', 'transformer.h.9.crossattention.c_proj.weight', 'transformer.h.9.crossattention.c_proj.bias', 'transformer.h.0.crossattention.c_proj.weight', 'transformer.h.2.crossattention.c_attn.weight', 'transformer.h.0.ln_cross_attn.weight', 'transformer.h.11.crossattention.bias', 'transformer.h.4.ln_cross_attn.weight', 'transformer.h.2.crossattention.c_proj.weight', 'transformer.h.3.crossattention.q_attn.weight', 'transformer.h.9.crossattention.bias', 'transformer.h.4.crossattention.masked_bias', 'transformer.h.1.crossattention.c_proj.bias', 'transformer.h.9.ln_cross_attn.weight', 'transformer.h.5.crossattention.c_proj.weight', 'transformer.h.3.crossattention.bias', 'transformer.h.9.crossattention.c_attn.weight', 'transformer.h.1.crossattention.masked_bias', 'transformer.h.8.crossattention.c_proj.bias', 'transformer.h.7.crossattention.bias', 'transformer.h.1.crossattention.c_attn.weight', 'transformer.h.5.crossattention.c_attn.weight', 'transformer.h.7.crossattention.c_proj.bias', 'transformer.h.0.crossattention.q_attn.weight', 'transformer.h.5.crossattention.masked_bias', 'transformer.h.7.crossattention.c_proj.weight', 'transformer.h.5.crossattention.bias', 'transformer.h.7.ln_cross_attn.weight', 'transformer.h.11.crossattention.c_proj.bias', 'transformer.h.1.crossattention.q_attn.weight', 'transformer.h.9.crossattention.masked_bias', 'transformer.h.11.crossattention.q_attn.weight', 'transformer.h.1.crossattention.bias', 'transformer.h.7.crossattention.c_attn.weight', 'transformer.h.10.crossattention.masked_bias', 'transformer.h.3.crossattention.c_attn.weight', 'transformer.h.2.crossattention.c_proj.bias', 'transformer.h.4.crossattention.q_attn.weight', 'transformer.h.6.ln_cross_attn.weight', 'transformer.h.10.ln_cross_attn.weight', 'transformer.h.4.crossattention.c_proj.weight', 'transformer.h.5.ln_cross_attn.weight', 'transformer.h.10.crossattention.bias', 'transformer.h.5.crossattention.q_attn.weight', 'transformer.h.6.crossattention.c_proj.weight', 'transformer.h.10.crossattention.c_proj.bias', 'transformer.h.11.crossattention.masked_bias', 'transformer.h.6.crossattention.c_proj.bias', 'transformer.h.8.ln_cross_attn.weight', 'transformer.h.4.crossattention.c_proj.bias', 'transformer.h.4.crossattention.c_attn.weight', 'transformer.h.1.crossattention.c_proj.weight', 'transformer.h.3.crossattention.c_proj.weight', 'transformer.h.0.crossattention.c_proj.bias', 'transformer.h.0.crossattention.bias', 'transformer.h.8.crossattention.bias', 'transformer.h.10.crossattention.c_attn.weight', 'transformer.h.7.crossattention.q_attn.weight', 'transformer.h.11.crossattention.c_attn.weight', 'transformer.h.9.crossattention.q_attn.weight', 'transformer.h.2.crossattention.q_attn.weight', 'transformer.h.11.crossattention.c_proj.weight', 'transformer.h.1.ln_cross_attn.weight', 'transformer.h.6.crossattention.q_attn.weight', 'transformer.h.8.crossattention.masked_bias', 'transformer.h.8.crossattention.q_attn.weight', 'transformer.h.2.crossattention.masked_bias', 'transformer.h.8.crossattention.c_attn.weight', 'transformer.h.7.crossattention.masked_bias', 'transformer.h.5.crossattention.c_proj.bias', 'transformer.h.3.crossattention.masked_bias', 'transformer.h.0.crossattention.masked_bias', 'transformer.h.2.ln_cross_attn.weight', 'transformer.h.8.crossattention.c_proj.weight', 'transformer.h.11.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# loading pretrained model\n",
    "encoder_decoder = EncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder_pretrained_model_name_or_path=ENCODER_PRETRAINED,\n",
    "    decoder_pretrained_model_name_or_path=DECODER_PRETRAINED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jBVyNeKUv6FU"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqTrain(pl.LightningModule):\n",
    "    def __init__(self, encoder_decoder):\n",
    "        super().__init__()\n",
    "        self.encoder_decoder = encoder_decoder\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        return self.encoder_decoder(\n",
    "                **batch\n",
    "            )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        self.log('loss', outputs.loss)\n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        self.log('val_loss', outputs.loss)\n",
    "        return outputs.loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        encoder_params = list(\n",
    "            {\"params\":param,\"lr\":1e-5}\n",
    "            for param in self.encoder_decoder.encoder.embeddings.parameters()) +\\\n",
    "            list({\"params\":param,\"lr\":1e-5}\n",
    "            for param in self.encoder_decoder.encoder.encoder.parameters()) +\\\n",
    "            list({\"params\":param,\"lr\":1e-3}\n",
    "            for param in self.encoder_decoder.encoder.pooler.parameters())\n",
    "\n",
    "        decoder_params = list()\n",
    "        for name, param in self.encoder_decoder.decoder.named_parameters():\n",
    "            if 'ln_cross_attn' in name:\n",
    "                decoder_params.append({\"params\":param,\"lr\":1e-3})\n",
    "            elif 'crossattention' in name:\n",
    "                decoder_params.append({\"params\":param,\"lr\":1e-3})\n",
    "            elif 'lm_head' in name:\n",
    "                decoder_params.append({\"params\":param,\"lr\":1e-4})\n",
    "            else:\n",
    "                decoder_params.append({\"params\":param,\"lr\":1e-5})\n",
    "\n",
    "        return torch.optim.Adam(\n",
    "                encoder_params + decoder_params,\n",
    "                lr=1e-3,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "5uIjcPuXw0Fr"
   },
   "outputs": [],
   "source": [
    "module = Seq2SeqTrain(encoder_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBf3NTKSLcUb"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "save = pl.callbacks.ModelCheckpoint(\n",
    "    '/GCI/transformers/weights/cc_to_zh',\n",
    "    save_top_k=2,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=[1],\n",
    "    max_epochs=10,\n",
    "    callbacks=[save],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name            | Type                | Params\n",
      "--------------------------------------------------------\n",
      "0 | encoder_decoder | EncoderDecoderModel | 233 M \n",
      "--------------------------------------------------------\n",
      "233 M     Trainable params\n",
      "0         Non-trainable params\n",
      "233 M     Total params\n",
      "935.203   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e24592063e457da4259fab0911e194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(module, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "579055f403bf4594a2c665adfdfb8995": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "659eee19636c45da881d243f66aedf27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94111dfb9a2d4a4f93e00bdb34c70090": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff2e02e62d0b438cac9f521da8c0d5eb",
       "IPY_MODEL_fc66ee3afa1944beb42494efbb1301ac",
       "IPY_MODEL_9ac2a1e65c084bca8cdff9f1dc7541e0"
      ],
      "layout": "IPY_MODEL_659eee19636c45da881d243f66aedf27"
     }
    },
    "94765776469249ea94eee8ccf64c47e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ac2a1e65c084bca8cdff9f1dc7541e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94765776469249ea94eee8ccf64c47e7",
      "placeholder": "​",
      "style": "IPY_MODEL_579055f403bf4594a2c665adfdfb8995",
      "value": " 1/1 [00:00&lt;00:00, 21.65it/s]"
     }
    },
    "b3486fd1f15b43068e47df0ad6a81559": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb2e04bed86047b0b3a4e587cfb48ef0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8dad1a95c8646edbde1af6fcc3f0ff9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db73dbc0dabc429481860871b02dc9e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc66ee3afa1944beb42494efbb1301ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb2e04bed86047b0b3a4e587cfb48ef0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8dad1a95c8646edbde1af6fcc3f0ff9",
      "value": 1
     }
    },
    "ff2e02e62d0b438cac9f521da8c0d5eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3486fd1f15b43068e47df0ad6a81559",
      "placeholder": "​",
      "style": "IPY_MODEL_db73dbc0dabc429481860871b02dc9e0",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
